import multiprocessing
multiprocessing.set_start_method('spawn', force=True)
import torch
from torch.utils.data import DataLoader
import torchvision.transforms as T
from dataset_attr import DeepFashionAttrDataset
from model import AttributeResNet
import torch.nn as nn
import torch.optim as optim
import os
from tqdm import tqdm

def main():
    # ===== 1. CUDA è¨­å®š =====
    torch.cuda.set_device(0)
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    print("âœ… ä½¿ç”¨è£ç½®ï¼š", device)
    if device.type == 'cuda':
        print("âœ… GPU åç¨±ï¼š", torch.cuda.get_device_name(0))

    # ===== 2. è³‡æ–™è¨­å®š =====
    img_root = 'DeepFashion'
    attr_file = 'DeepFashion/Anno_coarse/list_attr_img.txt'
    eval_file = 'DeepFashion/Eval/list_eval_partition.txt'

    transform = T.Compose([
        T.Resize((224, 224)),
        T.ToTensor(),
        T.Normalize(mean=[0.5]*3, std=[0.5]*3)
    ])

    # ===== 3. Dataset & Dataloaderï¼ˆå„ªåŒ–ï¼‰ =====
    train_dataset = DeepFashionAttrDataset(img_root, attr_file, eval_file, mode='train', transform=transform, max_items=None)
    val_dataset = DeepFashionAttrDataset(img_root, attr_file, eval_file, mode='val', transform=transform, max_items=10000)

    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=64, num_workers=4, pin_memory=True)

    # ===== 4. æ¨¡å‹èˆ‡è¨“ç·´åƒæ•¸ =====
    model = AttributeResNet(num_labels=1000).to(device)
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    # ===== 5. è¨“ç·´æµç¨‹ =====
    best_val_loss = float('inf')
    for epoch in range(10):  # èª¿æ•´ epoch æ•¸é‡
        print(f"\nğŸ“˜ Epoch {epoch+1}")
        model.train()
        total_loss = 0
        progress_bar = tqdm(train_loader, desc="ğŸŸ¢ Training", leave=False)

        for images, labels in progress_bar:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            progress_bar.set_postfix(loss=loss.item())

        print(f"[Epoch {epoch+1}] Training Loss: {total_loss:.4f}")

        # é©—è­‰
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()

        print(f"[Epoch {epoch+1}] Validation Loss: {val_loss:.4f}")

        # å„²å­˜æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            os.makedirs('saved_models', exist_ok=True)
            torch.save(model.state_dict(), 'saved_models/best_tagger.pth')
            print("âœ… Saved best model!")

# âœ… Windows ä¸Šå¿…åŠ é€™æ®µ
if __name__ == '__main__':
    main()
